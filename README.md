# üìâ Predicci√≥n de Churn en Telecomunicaciones

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![Scikit-Learn](https://img.shields.io/badge/Library-Scikit--Learn-orange)
![Status](https://img.shields.io/badge/Status-Finalizado-green)

> **Resumen:** Soluci√≥n End-to-End de Machine Learning para predecir la fuga de clientes (Churn) en una empresa de telecomunicaciones. Incluye limpieza de datos, an√°lisis exploratorio, modelado con Random Forest y un Pipeline automatizado listo para producci√≥n.

---

## üìñ Contexto del Proyecto
La p√©rdida de clientes (Churn) es uno de los desaf√≠os m√°s costosos en la industria de las telecomunicaciones. Este proyecto analiza datos hist√≥ricos para:
1.  **Entender:** ¬øPor qu√© se van los clientes?
2.  **Predecir:** ¬øQu√© clientes tienen alta probabilidad de irse el pr√≥ximo mes?
3.  **Actuar:** Dise√±ar estrategias de retenci√≥n basadas en datos.

---

## üìÇ Diccionario de Datos
El modelo fue entrenado utilizando un dataset consolidado con las siguientes variables clave:

| Variable | Tipo | Descripci√≥n | Ejemplo |
| :--- | :--- | :--- | :--- |
| `customer_id` | Texto | ID √∫nico del cliente (No utilizado en predicci√≥n) | `7590-VHVEG` |
| `tenure` | Num√©rico | Meses que el cliente ha permanecido en la empresa | `12`, `24` |
| `monthly_charges` | Num√©rico | Monto mensual facturado | `29.85` |
| `total_charges` | Num√©rico | Monto total facturado hist√≥rico | `1889.50` |
| `contract_type` | Categ√≥rico | Tipo de contrato (Factor cr√≠tico) | `Month-to-month`, `Two year` |
| `payment_method` | Categ√≥rico | Medio de pago utilizado | `Electronic check`, `Credit card` |
| `internet_service` | Categ√≥rico | Tipo de servicio de internet | `Fiber optic`, `DSL`, `No` |
| `churn` | Target | **Variable Objetivo:** ¬øEl cliente cancel√≥? | `0` (No), `1` (S√≠) |

---

## üõ†Ô∏è Tecnolog√≠as y Herramientas
* **Lenguaje:** Python
* **ETL & An√°lisis:** Pandas, NumPy
* **Visualizaci√≥n:** Seaborn, Matplotlib
* **Machine Learning:** Scikit-Learn (Random Forest, Pipeline, ColumnTransformer)
* **Control de Versiones:** Git/GitHub

---

## ‚öôÔ∏è Arquitectura del Proyecto

El desarrollo se estructur√≥ en 4 fases principales:

1.  **Ingenier√≠a de Datos (ETL):** Limpieza de nulos, tratamiento de duplicados y transformaci√≥n de tipos.
2.  **EDA (An√°lisis Exploratorio):** Detecci√≥n de patrones y correlaciones.
3.  **Modelado:** Entrenamiento y validaci√≥n de algoritmos.
4.  **Deployment:** Creaci√≥n de un Pipeline serializado.

### üîÑ Flujo del Pipeline (Model Workflow)
El siguiente diagrama ilustra c√≥mo el artefacto `.joblib` procesa los datos autom√°ticamente:

```mermaid
graph TD;
    %% --- DEFINICI√ìN DE CLASES (La Paleta de Colores) ---
    %% Input: Morado Profundo (Indica inicio/datos)
    classDef entrada fill:#4A148C,stroke:#B39DDB,stroke-width:2px,color:#fff,font-weight:bold;
    
    %% Procesos: Gris Azulado (Neutro para pasos intermedios)
    classDef proceso fill:#37474F,stroke:#90A4AE,stroke-width:1px,color:#fff,font-weight:bold;
    
    %% Decisi√≥n: Naranja Ladrillo (Visible pero no chill√≥n)
    classDef decision fill:#E65100,stroke:#FFCC80,stroke-width:2px,color:#fff,font-weight:bold;
    
    %% Modelo: Azul Profundo (Tecnol√≥gico)
    classDef modelo fill:#0D47A1,stroke:#64B5F6,stroke-width:2px,color:#fff,font-weight:bold;
    
    %% Salida: Verde Bosque (√âxito/Resultado)
    classDef salida fill:#1B5E20,stroke:#81C784,stroke-width:2px,color:#fff,font-weight:bold;

    %% --- EL DIAGRAMA ---
    A["Datos Crudos (Raw Data)"]:::entrada --> B("Preprocesador: ColumnTransformer");
    B:::proceso --> C{"¬øTipo de Variable?"};
    
    C:::decision -- Num√©rica --> D["Passthrough (Sin cambios)"];
    C:::decision -- Categ√≥rica --> E["One-Hot Encoding"];
    
    D:::proceso --> F["Concatenaci√≥n"];
    E:::proceso --> F:::proceso;
    
    F --> G("Modelo: Random Forest Classifier");
    G:::modelo --> H["Predicci√≥n Final (0 o 1)"];
    H:::salida
```
## üìä Resultados e Insights de Negocio

El modelo **Random Forest** alcanz√≥ un **Accuracy aproximado del 90%** en el set de prueba. Basado en la importancia de las variables (Feature Importance), se generaron las siguientes recomendaciones:

1.  **Alerta en Contratos Mensuales:** Los clientes con contrato "Month-to-month" son los m√°s propensos a irse.
    * *Estrategia:* Ofrecer descuentos por migraci√≥n a planes anuales.
2.  **Riesgo en Nuevos Clientes:** La tasa de cancelaci√≥n es cr√≠tica en los primeros meses (`tenure` bajo).
    * *Estrategia:* Programa de "Onboarding VIP" durante los primeros 90 d√≠as.
3.  **Sensibilidad al Precio:** Usuarios con cargos altos sin servicios premium tienden a rotar.
    * *Estrategia:* Revisi√≥n de planes y oferta de beneficios exclusivos.

---

## üöÄ C√≥mo usar este proyecto

### 1. Clonar el repositorio
```bash
git clone [https://github.com/DaisyQuinteros/ChurnInsight.git](https://github.com/DaisyQuinteros/ChurnInsight.git)
```
### 2. Cargar el Modelo (Para integraci√≥n en Backend)
El proyecto entrega un archivo `pipeline_churninsight_v1.joblib` que acepta datos crudos.

```import joblib
import pandas as pd

# Cargar el pipeline
# Aseg√∫rate de que el archivo .joblib est√© en la misma carpeta o ajusta la ruta
modelo = joblib.load('pipeline_churninsight_v1.joblib')

# Ejemplo de cliente nuevo (Datos crudos como vienen de la web)
nuevo_cliente = pd.DataFrame([{
    'contract_type': 'Month-to-month',
    'monthly_charges': 70.5,
    'tenure': 2,
    'payment_method': 'Electronic check',
    # ... otras columnas requeridas por el modelo
}])

# Predicci√≥n (0 = Se queda, 1 = Se va)
prediccion = modelo.predict(nuevo_cliente)
print(f"Predicci√≥n de Churn: {prediccion[0]}")
```

## ‚öôÔ∏è Instrucciones de Ejecuci√≥n

Para replicar el an√°lisis o explorar el c√≥digo paso a paso:

### 1. Prerrequisitos
Instalar las dependencias necesarias ejecutando:
```bash
pip install -r requirements.txt
```
### 2. Orden de los Notebooks
El proyecto se estructura en dos etapas l√≥gicas. Se recomienda seguir este orden de lectura/ejecuci√≥n:

#### Paso 1: ETL y Preparaci√≥n

- Abrir: preparacion_de_las_bases_de_datos.ipynb
- Descripci√≥n: Este notebook procesa los archivos CSV crudos (base_clientes_real.csv, etc.), realiza la limpieza y genera el dataset maestro.

#### Paso 2: An√°lisis y Modelado

- Abrir: proyecto_churninsight_prediccion_de_cancelacion_de_clientes.ipynb
- Descripci√≥n: Contiene el An√°lisis Exploratorio de Datos (EDA), el entrenamiento del modelo Random Forest y la exportaci√≥n de los pipelines.

## üìÇ Estructura de Archivos
```text
‚îú‚îÄ‚îÄ base_clientes_real.csv                                              # (y otros csv) Datos crudos
‚îú‚îÄ‚îÄ churn_dataset_procesado_V1.csv                                      # Dataset final limpio
‚îú‚îÄ‚îÄ preparacion_de_las_bases_de_datos.ipynb                             # Notebook de ETL
‚îú‚îÄ‚îÄ proyecto_churninsight_prediccion_de_cancelacion_de_clientes.ipynb   # Notebook de An√°lisis/Modelo
‚îú‚îÄ‚îÄ pipeline_churninsight_v1.joblib                                     # Pipeline listo para producci√≥n
‚îú‚îÄ‚îÄ modelo_churninsight_random_forest.joblib                            # Modelo entrenado
‚îú‚îÄ‚îÄ README.md                                                           # Documentaci√≥n del proyecto
‚îî‚îÄ‚îÄ requirements.txt                                                    # Librer√≠as necesarias
```
---

## ‚úíÔ∏è Autor
**Daisy Quinteros Silva**
* **Rol:** Data Scientist / Ingeniero en Inform√°tica
* [LinkedIn](www.linkedin.com/in/daisy-quinteros-silva-5b0450a5)


---
*Proyecto aplicado en la simulaci√≥n laboral de No Country, utilizando conocimientos del programa ONE - Alura Latam.*
