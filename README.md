# ğŸ“‰ PredicciÃ³n de Churn en Telecomunicaciones

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![Scikit-Learn](https://img.shields.io/badge/Library-Scikit--Learn-orange)
![Status](https://img.shields.io/badge/Status-Finalizado-green)

> **Resumen:** SoluciÃ³n End-to-End de Machine Learning para predecir la fuga de clientes (Churn) en una empresa de telecomunicaciones. Incluye limpieza de datos, anÃ¡lisis exploratorio, modelado con Random Forest y un Pipeline automatizado listo para producciÃ³n.

---

## ğŸ“– Contexto del Proyecto
La pÃ©rdida de clientes (Churn) es uno de los desafÃ­os mÃ¡s costosos en la industria de las telecomunicaciones. Este proyecto analiza datos histÃ³ricos para:
1.  **Entender:** Â¿Por quÃ© se van los clientes?
2.  **Predecir:** Â¿QuÃ© clientes tienen alta probabilidad de irse el prÃ³ximo mes?
3.  **Actuar:** DiseÃ±ar estrategias de retenciÃ³n basadas en datos.

---

## ğŸ“‚ Diccionario de Datos
El modelo fue entrenado utilizando un dataset consolidado con las siguientes variables clave:

| Variable | Tipo | DescripciÃ³n | Ejemplo |
| :--- | :--- | :--- | :--- |
| `customer_id` | Texto | ID Ãºnico del cliente (No utilizado en predicciÃ³n) | `7590-VHVEG` |
| `tenure` | NumÃ©rico | Meses que el cliente ha permanecido en la empresa | `12`, `24` |
| `monthly_charges` | NumÃ©rico | Monto mensual facturado | `29.85` |
| `total_charges` | NumÃ©rico | Monto total facturado histÃ³rico | `1889.50` |
| `contract_type` | CategÃ³rico | Tipo de contrato (Factor crÃ­tico) | `Month-to-month`, `Two year` |
| `payment_method` | CategÃ³rico | Medio de pago utilizado | `Electronic check`, `Credit card` |
| `internet_service` | CategÃ³rico | Tipo de servicio de internet | `Fiber optic`, `DSL`, `No` |
| `churn` | Target | **Variable Objetivo:** Â¿El cliente cancelÃ³? | `0` (No), `1` (SÃ­) |

---

## ğŸ› ï¸ TecnologÃ­as y Herramientas
* **Lenguaje:** Python
* **ETL & AnÃ¡lisis:** Pandas, NumPy
* **VisualizaciÃ³n:** Seaborn, Matplotlib
* **Machine Learning:** Scikit-Learn (Random Forest, Pipeline, ColumnTransformer)
* **Control de Versiones:** Git/GitHub

---

## âš™ï¸ Arquitectura del Proyecto

El desarrollo se estructurÃ³ en 4 fases principales:

1.  **IngenierÃ­a de Datos (ETL):** Limpieza de nulos, tratamiento de duplicados y transformaciÃ³n de tipos.
2.  **EDA (AnÃ¡lisis Exploratorio):** DetecciÃ³n de patrones y correlaciones.
3.  **Modelado:** Entrenamiento y validaciÃ³n de algoritmos.
4.  **Deployment:** CreaciÃ³n de un Pipeline serializado.

### ğŸ”„ Flujo del Pipeline (Model Workflow)
El siguiente diagrama ilustra cÃ³mo el artefacto `.joblib` procesa los datos automÃ¡ticamente:

```mermaid
graph TD;
    %% --- DEFINICIÃ“N DE CLASES (La Paleta de Colores) ---
    %% Input: Morado Profundo (Indica inicio/datos)
    classDef entrada fill:#4A148C,stroke:#B39DDB,stroke-width:2px,color:#fff,font-weight:bold;
    
    %% Procesos: Gris Azulado (Neutro para pasos intermedios)
    classDef proceso fill:#37474F,stroke:#90A4AE,stroke-width:1px,color:#fff,font-weight:bold;
    
    %% DecisiÃ³n: Naranja Ladrillo (Visible pero no chillÃ³n)
    classDef decision fill:#E65100,stroke:#FFCC80,stroke-width:2px,color:#fff,font-weight:bold;
    
    %% Modelo: Azul Profundo (TecnolÃ³gico)
    classDef modelo fill:#0D47A1,stroke:#64B5F6,stroke-width:2px,color:#fff,font-weight:bold;
    
    %% Salida: Verde Bosque (Ã‰xito/Resultado)
    classDef salida fill:#1B5E20,stroke:#81C784,stroke-width:2px,color:#fff,font-weight:bold;

    %% --- EL DIAGRAMA ---
    A["Datos Crudos (Raw Data)"]:::entrada --> B("Preprocesador: ColumnTransformer");
    B:::proceso --> C{"Â¿Tipo de Variable?"};
    
    C:::decision -- NumÃ©rica --> D["Passthrough (Sin cambios)"];
    C:::decision -- CategÃ³rica --> E["One-Hot Encoding"];
    
    D:::proceso --> F["ConcatenaciÃ³n"];
    E:::proceso --> F:::proceso;
    
    F --> G("Modelo: Random Forest Classifier");
    G:::modelo --> H["PredicciÃ³n Final (0 o 1)"];
    H:::salida
```
## ğŸ“Š Resultados e Insights de Negocio

El modelo **Random Forest** alcanzÃ³ un **Accuracy aproximado del 90%** en el set de prueba. Basado en la importancia de las variables (Feature Importance), se generaron las siguientes recomendaciones:

1.  **Alerta en Contratos Mensuales:** Los clientes con contrato "Month-to-month" son los mÃ¡s propensos a irse.
    * *Estrategia:* Ofrecer descuentos por migraciÃ³n a planes anuales.
2.  **Riesgo en Nuevos Clientes:** La tasa de cancelaciÃ³n es crÃ­tica en los primeros meses (`tenure` bajo).
    * *Estrategia:* Programa de "Onboarding VIP" durante los primeros 90 dÃ­as.
3.  **Sensibilidad al Precio:** Usuarios con cargos altos sin servicios premium tienden a rotar.
    * *Estrategia:* RevisiÃ³n de planes y oferta de beneficios exclusivos.

---

## ğŸš€ CÃ³mo usar este proyecto

### 1. Clonar el repositorio
```bash
git clone [https://github.com/](https://github.com/)[TU-USUARIO]/[NOMBRE-REPO].git

### 2. Cargar el Modelo (Para integraciÃ³n en Backend)
El proyecto entrega un archivo `pipeline_churn_v1.joblib` que acepta datos crudos.

```python
import joblib
import pandas as pd

# Cargar el pipeline
modelo = joblib.load('models/pipeline_churn_v1.joblib')

# Ejemplo de cliente nuevo (Datos crudos como vienen de la web)
nuevo_cliente = pd.DataFrame([{
    'contract_type': 'Month-to-month',
    'monthly_charges': 70.5,
    'tenure': 2,
    'payment_method': 'Electronic check',
    # ... otras columnas requeridas
}])

# PredicciÃ³n (0 = Se queda, 1 = Se va)
prediccion = modelo.predict(nuevo_cliente)
print(f"PredicciÃ³n de Churn: {prediccion[0]}")
```

## ğŸ“‚ Estructura de Archivos
```text
â”œâ”€â”€ data/                # Dataset utilizado
â”œâ”€â”€ notebooks/           # Notebook con el anÃ¡lisis completo (.ipynb)
â”œâ”€â”€ models/              # Archivos .joblib listos para producciÃ³n
â”œâ”€â”€ README.md            # DocumentaciÃ³n del proyecto
â””â”€â”€ requirements.txt     # LibrerÃ­as necesarias
```
---

## âœ’ï¸ Autor
**Daisy Quinteros Silva**
* **Rol:** Data Scientist / Ingeniero en InformÃ¡tica
* [LinkedIn](www.linkedin.com/in/daisy-quinteros-silva-5b0450a5)


---
*Proyecto realizado como parte del programa ONE (Oracle Next Education) - Alura Latam.*
